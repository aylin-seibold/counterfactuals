---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  fig.height = 3,
  fig.width = 8
)
options(width = 200)
```

# counterfactuals

<!-- badges: start -->
[![R-CMD-check](https://github.com/susanne-207/counterfactuals/workflows/R-CMD-check/badge.svg)](https://github.com/susanne-207/counterfactuals/actions)
[![Codecov test coverage](https://codecov.io/gh/susanne-207/counterfactuals/branch/main/graph/badge.svg)](https://codecov.io/gh/susanne-207/counterfactuals?branch=main)
<!-- badges: end -->

`counterfactuals` provides various (model-agnostic) counterfactual explanation methods via a unified R6-based interface.

## Available methods

Currently available are the following methods:

- [Multi-Objective Counterfactual Explanations (MOC)](https://arxiv.org/abs/2004.11165)
- [NICE: An Algorithm for Nearest Instance Counterfactual Explanations (NICE)](https://arxiv.org/abs/2104.07411)
- [WhatIf](https://arxiv.org/abs/1907.04135)

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("susanne-207/counterfactuals")
```
## Get started

In this example, we train a `randomForest` on the `iris` dataset. 
We then examine how the feature values of a given `virginica` observation need to change in order for it to be classified as `versicolor` with a prediction probability of at least 0.5. 


```{r example, message=FALSE}
library(counterfactuals)
library(randomForest)
library(iml)
```

First, we train the randomForest model to predict the `Species`. Note that we leave out one observation from the
training data which is our `x_interest`.
```{r}
rf = randomForest(Species ~ ., data = iris[-150L, ])
```

We then create an `iml::Predictor` object, that holds the model and the data.

```{r}
predictor = Predictor$new(rf, type = "prob")
```

Now we set up an object of the counterfactual explanations method we want to use.
In this example, we use `WhatIf` and since we have a classification task we create an `WhatIfClassif` object.

```{r}
wi_classif = WhatIfClassif$new(predictor, n_counterfactuals = 5L)
```

For `x_interest` the model predicts:

```{r}
x_interest = iris[150L, ]
predictor$predict(x_interest)
```

We can use the `$find_counterfactuals()` method to find counterfactuals for `x_interest`.

```{r}
cfactuals = wi_classif$find_counterfactuals(
  x_interest, desired_class = "versicolor", desired_prob = c(0.5, 1)
)
```

The `cfactuals` object is now an instance of class `Counterfactuals`, which contains the counterfactuals and provides 
several methods for evaluation and plotting.

```{r}
cfactuals
```


The counterfactuals can be retrieved via `$data`.
```{r}
cfactuals$data
```
The `$predict` method shows the predictions for the counterfactuals.

```{r}
cbind(cfactuals$data, cfactuals$predict())
```


We can evaluate the counterfactuals according to various measures using the `$evaluate()` method.

```{r}
cfactuals$evaluate()
```

To examine the frequency of changes in each feature, we can use the `$plot_freq_of_feature_changes()` method.

```{r}
cfactuals$plot_freq_of_feature_changes()
```






